{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import time\n",
    "import os\n",
    "import hand_tracking as htm \n",
    "import numpy as np \n",
    "import screen_brightness_control as sbc \n",
    "from ctypes import cast, POINTER\n",
    "from comtypes import CLSCTX_ALL\n",
    "from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume \n",
    "import pyautogui \n",
    "from tkinter import *\n",
    "from tkinter import messagebox\n",
    "import tkinter\n",
    "import face_recognition\n",
    "\n",
    "\n",
    "# Defining Variables \n",
    "global wCam, hCam\n",
    "wCam, hCam = 480, 450 # Camera Resolution\n",
    "cap = cv2.VideoCapture(0)\n",
    "detector = htm.hand_detect(detectionCon=0.65, maxHands=1)\n",
    "\n",
    "successs = None\n",
    "global status\n",
    "global stat\n",
    "stat = 0\n",
    "status = []\n",
    "# cv2.useOptimized()\n",
    "\n",
    "\n",
    "            \n",
    "# Function for Screenshot Naming\n",
    "def screenshot_name():\n",
    "    timee = time.ctime()\n",
    "    t = timee.split(\" \")[:3]\n",
    "    inter_t = timee.split(\" \")\n",
    "    inter = inter_t[3].split(':')\n",
    "    st = ''\n",
    "    for i in inter:\n",
    "        st += i\n",
    "    strr = ''\n",
    "    for i in t:\n",
    "        strr += i\n",
    "    return str(strr + st) # Return current time and day\n",
    "\n",
    "\n",
    "\n",
    "# Function for Brightness\n",
    "def brightness():\n",
    "    print('Brightness Module Sucessfully Loaded')\n",
    "    br_bar = 0\n",
    "    br_per = 0\n",
    "    colorvol = 0\n",
    "    tipIds = [4, 8, 12, 16, 20]\n",
    "    pTime = 0\n",
    "    fingers = []\n",
    "    while(1):\n",
    "\n",
    "        frame, img = cap.read()\n",
    "        img = detector.find_hands(img, draw=True)\n",
    "        lmlist, bbox = detector.find_position(img, draw=True)\n",
    "\n",
    "        if len(lmlist) != 0:\n",
    "\n",
    "\n",
    "                # find distance b/w index & Thumb\n",
    "                lenth, img, lineinfo = detector.find_distance(4, 8, img)\n",
    "\n",
    "                # convert volume\n",
    "                # Finger Distance Range-> 50-300\n",
    "                # Volume Range-> -96.0 - 0.125\n",
    "                br_bar = np.interp(lenth, [8, 200], [400, 150])\n",
    "                br_per = np.interp(lenth, [8, 200], [0, 100])\n",
    "\n",
    "                # reduce resolution to make it smoother\n",
    "                smoothness = 5\n",
    "                br_level = smoothness * round(br_per / smoothness)\n",
    "\n",
    "                # check fingers up\n",
    "                # if pinky-finger is down to set volume\n",
    "                fingers = detector.fingerup()\n",
    "                if fingers[4] == 0 and fingers[2] == 0 and fingers[3] == 0 and fingers[0] == 1 and fingers[1] == 1:\n",
    "                    sbc.set_brightness(br_per)\n",
    "                    cv2.circle(\n",
    "                        img, (lineinfo[4], lineinfo[5]), 10, (0, 0, 255), cv2.FILLED)\n",
    "                    colorvol = (0, 0, 255)\n",
    "                    time.sleep(.1)\n",
    "                else:\n",
    "                    colorvol = (255, 0, 0)\n",
    "\n",
    "                if np.sum(fingers) == 5:\n",
    "                    cv2.destroyAllWindows()\n",
    "                    global stat\n",
    "                    slide()\n",
    "                    return\n",
    "\n",
    "        # Drawings\n",
    "        cv2.rectangle(img, (50, 150), (85, 400), (255, 0, 0), 2)\n",
    "        cv2.rectangle(img, (50, int(br_bar)), (85, 400),\n",
    "                      (255, 0, 0), cv2.FILLED)  # volume-bar\n",
    "        cv2.putText(img, f'{str(int(br_per))}%', (40, 450),\n",
    "                    cv2.FONT_HERSHEY_COMPLEX, 1, (255, 0, 0), 1)  # volume percentage\n",
    "\n",
    "        volset = int(sbc.get_brightness())\n",
    "        cv2.putText(img, f'Brightness Level:{str(int(volset))}', (280, 40),\n",
    "                    cv2.FONT_HERSHEY_COMPLEX, 1, colorvol, 2)  # set brightness number\n",
    "\n",
    "        # Frame Rate\n",
    "        cTime = time.time()\n",
    "        fps = 1 / (cTime - pTime)\n",
    "        pTime = cTime\n",
    "\n",
    "        cv2.putText(img, f'FPS:{str(int(fps))} ', (30, 60),\n",
    "                    cv2.FONT_HERSHEY_COMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "        cv2.imshow(\"brightness\", img)\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "\n",
    "        \n",
    "# Function for Volume Control\n",
    "def volume():\n",
    "    print('Volume Sucess')\n",
    "    devices = AudioUtilities.GetSpeakers()\n",
    "    interface = devices.Activate(IAudioEndpointVolume._iid_, CLSCTX_ALL, None)\n",
    "    volume = cast(interface, POINTER(IAudioEndpointVolume))\n",
    "    volrange = volume.GetVolumeRange()\n",
    "    minvol = volrange[0]\n",
    "    maxvol = volrange[1]\n",
    "    vol = 0\n",
    "    volbar = 300\n",
    "    volper = 0\n",
    "    bbox = []\n",
    "    area = 0\n",
    "    ptime = 0\n",
    "    smoothness = 0\n",
    "    colorvol = (255, 0, 0)\n",
    "    tipIds = [4, 8, 12, 16, 20]\n",
    "    fingers= []\n",
    "\n",
    "    while(1):\n",
    "        frame, img = cap.read()\n",
    "        img = detector.find_hands(img, draw=True)\n",
    "        lmlist, bbox = detector.find_position(img, draw=True)\n",
    "\n",
    "        if len(lmlist) != 0:\n",
    "\n",
    "            # filter based on size\n",
    "            area = (bbox[2]-bbox[0]) * (bbox[3]-bbox[1])//100\n",
    "\n",
    "\n",
    "            # find distance b/w index & Thumb\n",
    "            lenth, img, lineinfo = detector.find_distance(4, 8, img)\n",
    "\n",
    "            # convert volume\n",
    "            # Finger Distance Range-> 50-300\n",
    "            # Volume Range-> -96.0 - 0.125\n",
    "            volbar = np.interp(lenth, [8, 200], [400, 150])\n",
    "            volper = np.interp(lenth, [8, 200], [0, 100])\n",
    "\n",
    "            # reduce resolution to make it smoother\n",
    "            smoothness = 2\n",
    "            volper = smoothness * round(volper / smoothness)\n",
    "\n",
    "            # check fingers up\n",
    "            # if pinky-finger is down to set volume\n",
    "            fingers = detector.fingerup()\n",
    "                     \n",
    "            if fingers[4] == 0 and fingers[2] == 0 and fingers[3] == 0 and fingers[0] == 1 and fingers[1] == 1:\n",
    "                volume.SetMasterVolumeLevelScalar(volper/100, None)\n",
    "                cv2.circle(\n",
    "                    img, (lineinfo[4], lineinfo[5]), 10, (0, 0, 255), cv2.FILLED)\n",
    "                colorvol = (0, 0, 255)\n",
    "            else:\n",
    "                colorvol = (255, 0, 0)\n",
    "\n",
    "            if np.sum(fingers) == 5: \n",
    "                cv2.destroyAllWindows()\n",
    "                global stat\n",
    "                slide()\n",
    "                return\n",
    "\n",
    "            # Drawings\n",
    "            cv2.rectangle(img, (50, 150), (85, 400), (255, 0, 0), 2)\n",
    "            cv2.rectangle(img, (50, int(volbar)), (85, 400),\n",
    "                          (255, 0, 0), cv2.FILLED)  # volume-bar\n",
    "            cv2.putText(img, f'{str(int(volper))}%', (40, 450),\n",
    "                        cv2.FONT_HERSHEY_COMPLEX, 1, (255, 0, 0), 1)  # volume percentage\n",
    "            volset = int(volume.GetMasterVolumeLevelScalar() * 100)\n",
    "            cv2.putText(img, f'Vol Set:{str(int(volset))}', (450, 40),\n",
    "                        cv2.FONT_HERSHEY_COMPLEX, 1, colorvol, 2)  # set volume\n",
    "\n",
    "            # Frame Rate\n",
    "            ctime = time.time()\n",
    "            fps = 1 / ((ctime-ptime))  # calculate FPS\n",
    "            ptime = ctime\n",
    "            cv2.putText(img, f'FPS:{str(int(fps))} ', (30, 60),\n",
    "                        cv2.FONT_HERSHEY_COMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "            cv2.imshow('volume', img)\n",
    "            cv2.waitKey(1)\n",
    "\n",
    "            \n",
    "            \n",
    "# Minimize Maximize Function\n",
    "def min_max():\n",
    "    print('minimize maximize function called')\n",
    "    br_bar= 0\n",
    "    br_per= 0\n",
    "    colorvol= 0\n",
    "    tipIds = [4, 8, 12, 16, 20]\n",
    "    pTime= 0\n",
    "    lenth= 0\n",
    "    fingers = []\n",
    "    while(1):\n",
    "\n",
    "        frame, img= cap.read()\n",
    "        img= detector.find_hands(img, draw=True)\n",
    "        lmlist, bbox= detector.find_position(img, draw=True)\n",
    "\n",
    "        if len(lmlist) != 0:\n",
    "\n",
    "                #filter based on size\n",
    "                area= (bbox[2]-bbox[0]) * (bbox[3]-bbox[1])//100\n",
    "                fingers= detector.fingerup()\n",
    "                lenth, img, lineinfo= detector.find_distance(4,8,img)\n",
    " \n",
    "                    \n",
    "                if lenth < 100 and fingers[4] == 0 and fingers[2] == 0 and fingers[3] == 0 and fingers[0] == 1 and fingers[1] == 1:\n",
    "                    pyautogui.getActiveWindow().minimize()\n",
    "                if lenth > 130 and lenth < 250 and fingers[4] == 0 and fingers[2] == 0 and fingers[3] == 0 and fingers[0] == 1 and fingers[1] == 1:\n",
    "                    pyautogui.getActiveWindow().maximize()\n",
    "\n",
    "                if np.sum(fingers) == 5:\n",
    "                    cv2.destroyAllWindows()\n",
    "                    global stat\n",
    "                    slide()\n",
    "                    return\n",
    "\n",
    "                # Frame Rate\n",
    "                cTime = time.time()\n",
    "                fps = 1 / (cTime - pTime)\n",
    "                pTime = cTime\n",
    "\n",
    "                cv2.putText(img, f'FPS:{str(int(fps))} ', (30,60), cv2.FONT_HERSHEY_COMPLEX, 1, (255,0,0), 2)\n",
    "\n",
    "                cv2.imshow(\"Image\", img)\n",
    "                cv2.waitKey(1)\n",
    "            \n",
    "\n",
    "            \n",
    "# Function for Display size control (Zoom-in & Zoom-out)\n",
    "def zoom():\n",
    "    print('Zoom function called')\n",
    "    br_bar = 0\n",
    "    br_per = 0\n",
    "    colorvol = 0\n",
    "    tipIds = [4, 8, 12, 16, 20]\n",
    "    pTime = 0\n",
    "    lenth = 0\n",
    "    fingers= []\n",
    "    while(1):\n",
    "\n",
    "        frame, img = cap.read()\n",
    "        img = detector.find_hands(img, draw=True)\n",
    "        lmlist, bbox = detector.find_position(img, draw=True)\n",
    "\n",
    "        if len(lmlist) != 0:\n",
    "\n",
    "            # filter based on size\n",
    "            area = (bbox[2]-bbox[0]) * (bbox[3]-bbox[1])//100\n",
    "            fingers = detector.fingerup()\n",
    "\n",
    "            if lenth < 100 and fingers[4] == 0 and fingers[2] == 0 and fingers[3] == 0 and fingers[0] == 1 and fingers[1] == 1:\n",
    "                pyautogui.hotkey('ctrl', '+')\n",
    "                time.sleep(1)\n",
    "\n",
    "            if np.sum(fingers) == 5: \n",
    "                pyautogui.hotkey('ctrl', '0')\n",
    "                cv2.destroyAllWindows()\n",
    "                global stat\n",
    "                slide()\n",
    "                return\n",
    "\n",
    "            # Frame Rate\n",
    "            cTime = time.time()\n",
    "            fps = 1 / (cTime - pTime)\n",
    "            pTime = cTime\n",
    "\n",
    "            cv2.putText(img, f'FPS:{str(int(fps))} ', (30, 60),\n",
    "                        cv2.FONT_HERSHEY_COMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "            cv2.imshow(\"zoom\", img)\n",
    "            cv2.waitKey(1)\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------\n",
    "\n",
    "            \n",
    "# Function for Mode Detection\n",
    "def slide():\n",
    "    tipIds = [4, 8, 12, 16, 20]\n",
    "#     global cap\n",
    "\n",
    "    # Read Camera\n",
    "#     cap = cv2.VideoCapture(0)\n",
    "    cap.set(3, wCam)\n",
    "    cap.set(4, hCam)\n",
    "    while(1):\n",
    "        success, img = cap.read()\n",
    "        img = detector.find_hands(img)\n",
    "        lmlist, bbox = detector.find_position(img, draw=True)\n",
    "        fingers = []\n",
    "\n",
    "        # Detect Fingers\n",
    "        if len(lmlist) != 0:\n",
    "            fingers = detector.fingerup()\n",
    "        \n",
    "        # 1.) Play-Pause (Last three finger gesture)\n",
    "        if np.sum(fingers) == 3 and fingers[0] == 0 and fingers[1] == 0 and fingers[2] == 1 and fingers[3] == 1 and fingers[4] == 1:\n",
    "            print('play pause module')\n",
    "            pyautogui.press(\"playpause\")\n",
    "            time.sleep(1) # Time delay\n",
    "\n",
    "        # 2.) shut down (pinky finger)\n",
    "        if np.sum(fingers) == 1 and fingers[4] == 1 and fingers[0] == 0 and fingers[1] == 0  and fingers[2] ==0  and fingers[3] == 0:\n",
    "            print('shut down gesture captured')\n",
    "            ws = tkinter.Tk()\n",
    "            \n",
    "            res= tkinter.messagebox.askyesno('prompt' , 'Want to leave?')\n",
    "            if res == True:\n",
    "                os.system(\"shutdown /s /t 1\")\n",
    "            \n",
    "            elif res == False:\n",
    "                pass\n",
    "            else:\n",
    "                tkinter.messagebox.showerror('error', 'somthing went wrong!')\n",
    "            \n",
    "            ws.destroy()\n",
    "            ws.mainloop()\n",
    "            \n",
    "\n",
    "        # 3.) Brightness (Mode: Index Finger )\n",
    "        if np.sum(fingers) == 1 and fingers[1] == 1 and fingers[0] == 0 and fingers[2] == 0 and fingers[3] == 0 and fingers[4] == 0:\n",
    "            status.append(1)\n",
    "            print(\"Brightness Module\")\n",
    "#             cv2.destroyAllWindows()\n",
    "            brightness()\n",
    "            return\n",
    "\n",
    "        \n",
    "        # 4.) Zoom (Mode: Three fingers)\n",
    "        if np.sum(fingers) == 3 and fingers[1] == 1 and fingers[2] == 1 and fingers[3] == 1 and fingers[4] == 0 and fingers[0] == 0:\n",
    "            status.append(3)\n",
    "            print('zoom module')\n",
    "#             cv2.destroyAllWindows()\n",
    "            zoom()\n",
    "            return\n",
    "\n",
    "        \n",
    "        # 5.) Volume ( Mode: V - sign gesture)\n",
    "        if np.sum(fingers) == 2 and fingers[1] == 1 and fingers[2] == 1 and fingers[0] == 0 and fingers[3] == 0 and fingers[4] == 0:\n",
    "            status.append(2)\n",
    "#             cv2.destroyAllWindows()\n",
    "            volume()\n",
    "            return\n",
    "        \n",
    "        \n",
    "        # 6.) Minimize - Maximize (Mode: 4-fingers gesture)\n",
    "        if np.sum(fingers) == 4 and fingers[0] == 0 and fingers[1] == 1 and fingers[2] == 1 and fingers[3] == 1 and fingers[4] == 1:\n",
    "            status.append(4)\n",
    "#             cv2.destroyAllWindows()\n",
    "            min_max()\n",
    "            return\n",
    "        \n",
    "        \n",
    "        # 7.) Undo ( thumb and pinky finger gesture )\n",
    "        if np.sum(fingers) == 2 and fingers[4] == 1 and fingers[0] == 1 and fingers[1] == 0 and fingers[2] == 0 and fingers[3] == 0:\n",
    "            print('undo gesture captured')\n",
    "            pyautogui.keyDown('ctrl') \n",
    "            pyautogui.press('z')  \n",
    "            pyautogui.keyUp('ctrl') \n",
    "            time.sleep(2)\n",
    "        \n",
    "        \n",
    "        # 8.) Screenshot (index, pinky and thumb finger gesture)\n",
    "        if np.sum(fingers) == 3 and fingers[4] == 1 and fingers[1] == 1 and fingers[0] == 1 and fingers[2] == 0 and fingers[3] == 0:\n",
    "            lll = ''\n",
    "            scr = pyautogui.screenshot()\n",
    "\n",
    "            user_name = str(os.getcwd().split('\\\\')[2])\n",
    "            # user_name \n",
    "            pathh = (f\"/Users/{user_name}/Desktop/Gesture_SCR\")\n",
    "            # os.mkdir(pathh)\n",
    "            if not os.path.exists(pathh):\n",
    "                os.mkdir(pathh)\n",
    "\n",
    "            lll = screenshot_name()\n",
    "            scr.save(f\"{pathh}/{lll}.jpg\")\n",
    "            time.sleep(3)\n",
    "\n",
    "            \n",
    "        # 9.) Save (thumb gesture)\n",
    "        if np.sum(fingers) == 1 and fingers[0] == 1 and fingers[1] == 0 and fingers[3] == 0 and fingers[4] == 0 and fingers[2] == 0:\n",
    "            pyautogui.keyDown('ctrl')\n",
    "            pyautogui.press('s')\n",
    "            pyautogui.keyUp('ctrl')\n",
    "            time.sleep(2)\n",
    "\n",
    "        cv2.putText(img, '1. Brightness', (20, 50),\n",
    "                    cv2.FONT_HERSHEY_COMPLEX, 1, (255, 0, 0), 2)\n",
    "        cv2.putText(img, '2. Volume', (20, 100),\n",
    "                    cv2.FONT_HERSHEY_COMPLEX, 1, (255, 0, 0), 2)\n",
    "        cv2.imshow('img', img)\n",
    "        \n",
    "            \n",
    "        # 10.) (ALT + F4) ( index + thumb gesture )\n",
    "        if np.sum(fingers) == 2 and fingers[0] ==1 and fingers[1] == 1 and fingers[2] == 0 and fingers[3] == 0 and fingers[4] == 0:\n",
    "            pyautogui.getActiveWindowTitle()\n",
    "            time.sleep(0.5)\n",
    "            pyautogui.keyDown('alt')\n",
    "            pyautogui.press('F4')\n",
    "            pyautogui.keyUp('alt')\n",
    "        \n",
    "        # 11.) Restart ( Index + pinky finger gesture )\n",
    "        if fingers[0] ==0 and fingers[1] == 0 and fingers[2] == 0 and fingers[3] == 0 and fingers[4] == 0:\n",
    "            print('Restart gesture captured')\n",
    "            ws = tkinter.Tk()\n",
    "            \n",
    "            res= tkinter.messagebox.askyesno('prompt' , 'Want to leave?')\n",
    "            if res == True:\n",
    "                os.system(\"shutdown /r /t 1\")\n",
    "            \n",
    "            elif res == False:\n",
    "                pass\n",
    "            else:\n",
    "                tkinter.messagebox.showerror('error', 'somthing went wrong!')\n",
    "            \n",
    "            ws.destroy()\n",
    "            ws.mainloop()\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"e\"):\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Face Recongnition\n",
    "\n",
    "\n",
    "path= 'Attendees/'\n",
    "images= []\n",
    "img_names= []\n",
    "\n",
    "mylist= os.listdir(path)\n",
    "mylist= mylist[1:]\n",
    "\n",
    "for classes in mylist:\n",
    "    img= cv2.imread(f'{path}/{classes}')\n",
    "    images.append(img)\n",
    "    img_names.append(os.path.splitext(classes)[0])\n",
    "\n",
    "# print(img_names)\n",
    "\n",
    "encodlist= []\n",
    "def find_encodings(images):\n",
    "#     encodlist= []\n",
    "    for img in images:\n",
    "        img= cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        encods= face_recognition.face_encodings(img)[0]\n",
    "        encodlist.append(encods)\n",
    "    \n",
    "    return encodlist\n",
    "find_encodings(images)\n",
    "\n",
    "# cap= cv2.VideoCapture(0)\n",
    "# while True:\n",
    "#         frame, im= cap.read()\n",
    "#         img= cv2.resize(im, (0,0), None, 0.25, 0.25)\n",
    "#         img= cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "#         curfaces_in_frame= face_recognition.face_locations(img)\n",
    "#         encod_curframe= face_recognition.face_encodings(img, curfaces_in_frame) #finding encodings of img & current frame\n",
    "        \n",
    "#         for encodface, face_loc in zip(encod_curframe,curfaces_in_frame):\n",
    "#             match= face_recognition.compare_faces(encodlist, encodface)\n",
    "#             facedis= face_recognition.face_distance(encodlist, encodface)\n",
    "# #             print(facedis) # prints face distance\n",
    "#             match_index= np.argmin(facedis)\n",
    "#             face_name= img_names[match_index]\n",
    "        \n",
    "#             if match[match_index]:\n",
    "#                 print(f\"Approved, {face_name}'s Face Detected\")\n",
    "#                 stat = slide()\n",
    "# #                 cap.release()\n",
    "#             else:\n",
    "#                 print('Accses Denied')\n",
    "# #                 cap.release()\n",
    "                \n",
    "                \n",
    "\n",
    "# Release the camera and all resources\n",
    "\n",
    "                \n",
    "# --------------------------------------------------------------------------------------------------\n",
    "\n",
    "            \n",
    "stat = slide()\n",
    "print(stat)\n",
    "if stat == 1:\n",
    "    status = []\n",
    "    stat = 0\n",
    "    brightness()\n",
    "if stat == 1 and status[0] == 2:\n",
    "    status = []\n",
    "    stat = 0\n",
    "    volume()\n",
    "if stat == 1 and status[0] == 3:\n",
    "    status = []\n",
    "    stat = 0\n",
    "    zoom()\n",
    "if stat == 1 and status[0] == 4:\n",
    "    status= []\n",
    "    stat = 0\n",
    "    min_max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Prototype (With Face Detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "create_int(): incompatible function arguments. The following argument types are supported:\n    1. (arg0: int) -> mediapipe.python._framework_bindings.packet.Packet\n\nInvoked with: 0.65",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3192/1908751325.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mwCam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhCam\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m480\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m450\u001b[0m \u001b[1;31m# Camera Resolution\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mcap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mdetector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhtm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhand_detect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdetectionCon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.65\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxHands\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0msuccesss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OpenCv\\SIH_Gesture_Control\\hand_tracking.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, mode, maxHands, detectionCon, trackCon)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmpHands\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolutions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhands\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         self.hands = self.mpHands.Hands(self.mode, self.maxHands,\n\u001b[0m\u001b[0;32m     23\u001b[0m                                         self.detectionCon, self.trackCon)\n\u001b[0;32m     24\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmpDraw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolutions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrawing_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mediapipe\\python\\solutions\\hands.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, static_image_mode, max_num_hands, model_complexity, min_detection_confidence, min_tracking_confidence)\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[0mhttps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0msolutions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmediapipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdev\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mhands\u001b[0m\u001b[1;31m#min_tracking_confidence.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \"\"\"\n\u001b[1;32m--> 114\u001b[1;33m     super().__init__(\n\u001b[0m\u001b[0;32m    115\u001b[0m         \u001b[0mbinary_graph_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_BINARYPB_FILE_PATH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         side_inputs={\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mediapipe\\python\\solution_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, binary_graph_path, graph_config, calculator_params, graph_options, side_inputs, outputs, stream_type_hints)\u001b[0m\n\u001b[0;32m    288\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobserve_output_stream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstream_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 290\u001b[1;33m     self._input_side_packets = {\n\u001b[0m\u001b[0;32m    291\u001b[0m         \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_packet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_side_input_type_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mside_inputs\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mediapipe\\python\\solution_base.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m     self._input_side_packets = {\n\u001b[1;32m--> 291\u001b[1;33m         \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_packet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_side_input_type_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    292\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mside_inputs\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m     }\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mediapipe\\python\\solution_base.py\u001b[0m in \u001b[0;36m_make_packet\u001b[1;34m(self, packet_data_type, data)\u001b[0m\n\u001b[0;32m    591\u001b[0m           data, image_format=image_frame.ImageFormat.SRGB)\n\u001b[0;32m    592\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpacket_creator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'create_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mpacket_data_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    594\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m   def _get_packet_content(self, packet_data_type: PacketDataType,\n",
      "\u001b[1;31mTypeError\u001b[0m: create_int(): incompatible function arguments. The following argument types are supported:\n    1. (arg0: int) -> mediapipe.python._framework_bindings.packet.Packet\n\nInvoked with: 0.65"
     ]
    }
   ],
   "source": [
    "import cv2 \n",
    "import time\n",
    "import os\n",
    "import hand_tracking as htm \n",
    "import numpy as np \n",
    "import screen_brightness_control as sbc \n",
    "from ctypes import cast, POINTER\n",
    "from comtypes import CLSCTX_ALL\n",
    "from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume \n",
    "import pyautogui \n",
    "from tkinter import *\n",
    "from tkinter import messagebox\n",
    "import tkinter\n",
    "import face_recognition\n",
    "\n",
    "\n",
    "# Defining Variables \n",
    "global wCam, hCam\n",
    "wCam, hCam = 480, 450 # Camera Resolution\n",
    "cap = cv2.VideoCapture(0)\n",
    "detector = htm.hand_detect(detectionCon=0.65, maxHands=1)\n",
    "\n",
    "successs = None\n",
    "global status\n",
    "global stat\n",
    "stat = 0\n",
    "status = []\n",
    "cv2.useOptimized()\n",
    "\n",
    "\n",
    "            \n",
    "# Function for Screenshot Naming\n",
    "def screenshot_name():\n",
    "    timee = time.ctime()\n",
    "    t = timee.split(\" \")[:3]\n",
    "    inter_t = timee.split(\" \")\n",
    "    inter = inter_t[3].split(':')\n",
    "    st = ''\n",
    "    for i in inter:\n",
    "        st += i\n",
    "    strr = ''\n",
    "    for i in t:\n",
    "        strr += i\n",
    "    return str(strr + st) # Return current time and day\n",
    "\n",
    "\n",
    "\n",
    "# Function for Brightness\n",
    "def brightness():\n",
    "    print('Brightness Module Sucessfully Loaded')\n",
    "    br_bar = 0\n",
    "    br_per = 0\n",
    "    colorvol = 0\n",
    "    tipIds = [4, 8, 12, 16, 20]\n",
    "    pTime = 0\n",
    "    fingers = []\n",
    "    while(1):\n",
    "\n",
    "        frame, img = cap.read()\n",
    "        img = detector.find_hands(img, draw=True)\n",
    "        lmlist, bbox = detector.find_position(img, draw=True)\n",
    "\n",
    "        if len(lmlist) != 0:\n",
    "\n",
    "\n",
    "                # find distance b/w index & Thumb\n",
    "                lenth, img, lineinfo = detector.find_distance(4, 8, img)\n",
    "\n",
    "                # convert volume\n",
    "                # Finger Distance Range-> 50-300\n",
    "                # Volume Range-> -96.0 - 0.125\n",
    "                br_bar = np.interp(lenth, [8, 200], [400, 150])\n",
    "                br_per = np.interp(lenth, [8, 200], [0, 100])\n",
    "\n",
    "                # reduce resolution to make it smoother\n",
    "                smoothness = 5\n",
    "                br_level = smoothness * round(br_per / smoothness)\n",
    "\n",
    "                # check fingers up\n",
    "                # if pinky-finger is down to set volume\n",
    "                fingers = detector.fingerup()\n",
    "                if fingers[4] == 0 and fingers[2] == 0 and fingers[3] == 0 and fingers[0] == 1 and fingers[1] == 1:\n",
    "                    sbc.set_brightness(br_per)\n",
    "                    cv2.circle(\n",
    "                        img, (lineinfo[4], lineinfo[5]), 10, (0, 0, 255), cv2.FILLED)\n",
    "                    colorvol = (0, 0, 255)\n",
    "                    time.sleep(.1)\n",
    "                else:\n",
    "                    colorvol = (255, 0, 0)\n",
    "\n",
    "                if np.sum(fingers) == 5:\n",
    "                    cv2.destroyAllWindows()\n",
    "                    global stat\n",
    "                    slide()\n",
    "                    return\n",
    "\n",
    "        # Drawings\n",
    "        cv2.rectangle(img, (50, 150), (85, 400), (255, 0, 0), 2)\n",
    "        cv2.rectangle(img, (50, int(br_bar)), (85, 400),\n",
    "                      (255, 0, 0), cv2.FILLED)  # volume-bar\n",
    "        cv2.putText(img, f'{str(int(br_per))}%', (40, 450),\n",
    "                    cv2.FONT_HERSHEY_COMPLEX, 1, (255, 0, 0), 1)  # volume percentage\n",
    "\n",
    "        volset = int(sbc.get_brightness())\n",
    "        cv2.putText(img, f'Brightness Level:{str(int(volset))}', (280, 40),\n",
    "                    cv2.FONT_HERSHEY_COMPLEX, 1, colorvol, 2)  # set brightness number\n",
    "\n",
    "        # Frame Rate\n",
    "        cTime = time.time()\n",
    "        fps = 1 / (cTime - pTime)\n",
    "        pTime = cTime\n",
    "\n",
    "        cv2.putText(img, f'FPS:{str(int(fps))} ', (30, 60),\n",
    "                    cv2.FONT_HERSHEY_COMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "        cv2.imshow(\"brightness\", img)\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "\n",
    "        \n",
    "# Function for Volume Control\n",
    "def volume():\n",
    "    print('Volume Sucess')\n",
    "    devices = AudioUtilities.GetSpeakers()\n",
    "    interface = devices.Activate(IAudioEndpointVolume._iid_, CLSCTX_ALL, None)\n",
    "    volume = cast(interface, POINTER(IAudioEndpointVolume))\n",
    "    volrange = volume.GetVolumeRange()\n",
    "    minvol = volrange[0]\n",
    "    maxvol = volrange[1]\n",
    "    vol = 0\n",
    "    volbar = 300\n",
    "    volper = 0\n",
    "    bbox = []\n",
    "    area = 0\n",
    "    ptime = 0\n",
    "    smoothness = 0\n",
    "    colorvol = (255, 0, 0)\n",
    "    tipIds = [4, 8, 12, 16, 20]\n",
    "    fingers= []\n",
    "\n",
    "    while(1):\n",
    "        frame, img = cap.read()\n",
    "        img = detector.find_hands(img, draw=True)\n",
    "        lmlist, bbox = detector.find_position(img, draw=True)\n",
    "\n",
    "        if len(lmlist) != 0:\n",
    "\n",
    "            # filter based on size\n",
    "            area = (bbox[2]-bbox[0]) * (bbox[3]-bbox[1])//100\n",
    "\n",
    "\n",
    "            # find distance b/w index & Thumb\n",
    "            lenth, img, lineinfo = detector.find_distance(4, 8, img)\n",
    "\n",
    "            # convert volume\n",
    "            # Finger Distance Range-> 50-300\n",
    "            # Volume Range-> -96.0 - 0.125\n",
    "            volbar = np.interp(lenth, [8, 200], [400, 150])\n",
    "            volper = np.interp(lenth, [8, 200], [0, 100])\n",
    "\n",
    "            # reduce resolution to make it smoother\n",
    "            smoothness = 2\n",
    "            volper = smoothness * round(volper / smoothness)\n",
    "\n",
    "            # check fingers up\n",
    "            # if pinky-finger is down to set volume\n",
    "            fingers = detector.fingerup()\n",
    "                     \n",
    "            if fingers[4] == 0 and fingers[2] == 0 and fingers[3] == 0 and fingers[0] == 1 and fingers[1] == 1:\n",
    "                volume.SetMasterVolumeLevelScalar(volper/100, None)\n",
    "                cv2.circle(\n",
    "                    img, (lineinfo[4], lineinfo[5]), 10, (0, 0, 255), cv2.FILLED)\n",
    "                colorvol = (0, 0, 255)\n",
    "            else:\n",
    "                colorvol = (255, 0, 0)\n",
    "\n",
    "            if np.sum(fingers) == 5: \n",
    "                cv2.destroyAllWindows()\n",
    "                global stat\n",
    "                slide()\n",
    "                return\n",
    "\n",
    "            # Drawings\n",
    "            cv2.rectangle(img, (50, 150), (85, 400), (255, 0, 0), 2)\n",
    "            cv2.rectangle(img, (50, int(volbar)), (85, 400),\n",
    "                          (255, 0, 0), cv2.FILLED)  # volume-bar\n",
    "            cv2.putText(img, f'{str(int(volper))}%', (40, 450),\n",
    "                        cv2.FONT_HERSHEY_COMPLEX, 1, (255, 0, 0), 1)  # volume percentage\n",
    "            volset = int(volume.GetMasterVolumeLevelScalar() * 100)\n",
    "            cv2.putText(img, f'Vol Set:{str(int(volset))}', (450, 40),\n",
    "                        cv2.FONT_HERSHEY_COMPLEX, 1, colorvol, 2)  # set volume\n",
    "\n",
    "            # Frame Rate\n",
    "            ctime = time.time()\n",
    "            fps = 1 / ((ctime-ptime))  # calculate FPS\n",
    "            ptime = ctime\n",
    "            cv2.putText(img, f'FPS:{str(int(fps))} ', (30, 60),\n",
    "                        cv2.FONT_HERSHEY_COMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "            cv2.imshow('volume', img)\n",
    "            cv2.waitKey(1)\n",
    "\n",
    "            \n",
    "            \n",
    "# Minimize Maximize Function\n",
    "def min_max():\n",
    "    print('minimize maximize function called')\n",
    "    br_bar= 0\n",
    "    br_per= 0\n",
    "    colorvol= 0\n",
    "    tipIds = [4, 8, 12, 16, 20]\n",
    "    pTime= 0\n",
    "    lenth= 0\n",
    "    fingers = []\n",
    "    while(1):\n",
    "\n",
    "        frame, img= cap.read()\n",
    "        img= detector.find_hands(img, draw=True)\n",
    "        lmlist, bbox= detector.find_position(img, draw=True)\n",
    "\n",
    "        if len(lmlist) != 0:\n",
    "\n",
    "                #filter based on size\n",
    "                area= (bbox[2]-bbox[0]) * (bbox[3]-bbox[1])//100\n",
    "                fingers= detector.fingerup()\n",
    "                lenth, img, lineinfo= detector.find_distance(4,8,img)\n",
    " \n",
    "                    \n",
    "                if lenth < 100 and fingers[4] == 0 and fingers[2] == 0 and fingers[3] == 0 and fingers[0] == 1 and fingers[1] == 1:\n",
    "                    pyautogui.getActiveWindow().minimize()\n",
    "                if lenth > 130 and lenth < 250 and fingers[4] == 0 and fingers[2] == 0 and fingers[3] == 0 and fingers[0] == 1 and fingers[1] == 1:\n",
    "                    pyautogui.getActiveWindow().maximize()\n",
    "\n",
    "                if np.sum(fingers) == 5:\n",
    "                    cv2.destroyAllWindows()\n",
    "                    global stat\n",
    "                    slide()\n",
    "                    return\n",
    "\n",
    "                # Frame Rate\n",
    "                cTime = time.time()\n",
    "                fps = 1 / (cTime - pTime)\n",
    "                pTime = cTime\n",
    "\n",
    "                cv2.putText(img, f'FPS:{str(int(fps))} ', (30,60), cv2.FONT_HERSHEY_COMPLEX, 1, (255,0,0), 2)\n",
    "\n",
    "                cv2.imshow(\"Image\", img)\n",
    "                cv2.waitKey(1)\n",
    "            \n",
    "\n",
    "            \n",
    "# Function for Display size control (Zoom-in & Zoom-out)\n",
    "def zoom():\n",
    "    print('Zoom function called')\n",
    "    br_bar = 0\n",
    "    br_per = 0\n",
    "    colorvol = 0\n",
    "    tipIds = [4, 8, 12, 16, 20]\n",
    "    pTime = 0\n",
    "    lenth = 0\n",
    "    fingers= []\n",
    "    while(1):\n",
    "\n",
    "        frame, img = cap.read()\n",
    "        img = detector.find_hands(img, draw=True)\n",
    "        lmlist, bbox = detector.find_position(img, draw=True)\n",
    "\n",
    "        if len(lmlist) != 0:\n",
    "\n",
    "            # filter based on size\n",
    "            area = (bbox[2]-bbox[0]) * (bbox[3]-bbox[1])//100\n",
    "            fingers = detector.fingerup()\n",
    "\n",
    "            if lenth < 100 and fingers[4] == 0 and fingers[2] == 0 and fingers[3] == 0 and fingers[0] == 1 and fingers[1] == 1:\n",
    "                pyautogui.hotkey('ctrl', '+')\n",
    "                time.sleep(1)\n",
    "\n",
    "            if np.sum(fingers) == 5: \n",
    "                pyautogui.hotkey('ctrl', '0')\n",
    "                cv2.destroyAllWindows()\n",
    "                global stat\n",
    "                slide()\n",
    "                return\n",
    "\n",
    "            # Frame Rate\n",
    "            cTime = time.time()\n",
    "            fps = 1 / (cTime - pTime)\n",
    "            pTime = cTime\n",
    "\n",
    "            cv2.putText(img, f'FPS:{str(int(fps))} ', (30, 60),\n",
    "                        cv2.FONT_HERSHEY_COMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "            cv2.imshow(\"zoom\", img)\n",
    "            cv2.waitKey(1)\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------\n",
    "\n",
    "            \n",
    "# Function for Mode Detection\n",
    "def slide():\n",
    "    tipIds = [4, 8, 12, 16, 20]\n",
    "\n",
    "\n",
    "    # Read Camera\n",
    "#     cap = cv2.VideoCapture(0)\n",
    "    cap.set(3, wCam)\n",
    "    cap.set(4, hCam)\n",
    "    while(1):\n",
    "        success, img = cap.read()\n",
    "        img = detector.find_hands(img)\n",
    "        lmlist, bbox = detector.find_position(img, draw=True)\n",
    "        fingers = []\n",
    "\n",
    "        # Detect Fingers\n",
    "        if len(lmlist) != 0:\n",
    "            fingers = detector.fingerup()\n",
    "        \n",
    "        # 1.) Play-Pause (Last three finger gesture)\n",
    "        if np.sum(fingers) == 3 and fingers[0] == 0 and fingers[1] == 0 and fingers[2] == 1 and fingers[3] == 1 and fingers[4] == 1:\n",
    "            print('play pause module')\n",
    "            pyautogui.press(\"playpause\")\n",
    "            time.sleep(1) # Time delay\n",
    "\n",
    "        # 2.) shut down (pinky finger)\n",
    "        if np.sum(fingers) == 1 and fingers[4] == 1 and fingers[0] == 0 and fingers[1] == 0  and fingers[2] ==0  and fingers[3] == 0:\n",
    "            print('shut down gesture captured')\n",
    "            ws = tkinter.Tk()\n",
    "            \n",
    "            res= tkinter.messagebox.askyesno('prompt' , 'Want to leave?')\n",
    "            if res == True:\n",
    "                os.system(\"shutdown /s /t 1\")\n",
    "            \n",
    "            elif res == False:\n",
    "                pass\n",
    "            else:\n",
    "                tkinter.messagebox.showerror('error', 'somthing went wrong!')\n",
    "            \n",
    "            ws.destroy()\n",
    "            ws.mainloop()\n",
    "            \n",
    "\n",
    "        # 3.) Brightness (Mode: Index Finger )\n",
    "        if np.sum(fingers) == 1 and fingers[1] == 1 and fingers[0] == 0 and fingers[2] == 0 and fingers[3] == 0 and fingers[4] == 0:\n",
    "            status.append(1)\n",
    "            print(\"Brightness Module\")\n",
    "#             cv2.destroyAllWindows()\n",
    "            brightness()\n",
    "            return\n",
    "\n",
    "        \n",
    "        # 4.) Zoom (Mode: Three fingers)\n",
    "        if np.sum(fingers) == 3 and fingers[1] == 1 and fingers[2] == 1 and fingers[3] == 1 and fingers[4] == 0 and fingers[0] == 0:\n",
    "            status.append(3)\n",
    "            print('zoom module')\n",
    "#             cv2.destroyAllWindows()\n",
    "            zoom()\n",
    "            return\n",
    "\n",
    "        \n",
    "        # 5.) Volume ( Mode: V - sign gesture)\n",
    "        if np.sum(fingers) == 2 and fingers[1] == 1 and fingers[2] == 1 and fingers[0] == 0 and fingers[3] == 0 and fingers[4] == 0:\n",
    "            status.append(2)\n",
    "#             cv2.destroyAllWindows()\n",
    "            volume()\n",
    "            return\n",
    "        \n",
    "        \n",
    "        # 6.) Minimize - Maximize (Mode: 4-fingers gesture)\n",
    "        if np.sum(fingers) == 4 and fingers[0] == 0 and fingers[1] == 1 and fingers[2] == 1 and fingers[3] == 1 and fingers[4] == 1:\n",
    "            status.append(4)\n",
    "#             cv2.destroyAllWindows()\n",
    "            min_max()\n",
    "            return\n",
    "        \n",
    "        \n",
    "        # 7.) Undo ( thumb and pinky finger gesture )\n",
    "        if np.sum(fingers) == 2 and fingers[4] == 1 and fingers[0] == 1 and fingers[1] == 0 and fingers[2] == 0 and fingers[3] == 0:\n",
    "            print('undo gesture captured')\n",
    "            pyautogui.keyDown('ctrl') \n",
    "            pyautogui.press('z')  \n",
    "            pyautogui.keyUp('ctrl') \n",
    "            time.sleep(2)\n",
    "        \n",
    "        \n",
    "        # 8.) Screenshot (index, pinky and thumb finger gesture)\n",
    "        if np.sum(fingers) == 3 and fingers[4] == 1 and fingers[1] == 1 and fingers[0] == 1 and fingers[2] == 0 and fingers[3] == 0:\n",
    "            lll = ''\n",
    "            scr = pyautogui.screenshot()\n",
    "\n",
    "            user_name = str(os.getcwd().split('\\\\')[2])\n",
    "            # user_name \n",
    "            pathh = (f\"/Users/{user_name}/Desktop/Gesture_SCR\")\n",
    "            # os.mkdir(pathh)\n",
    "            if not os.path.exists(pathh):\n",
    "                os.mkdir(pathh)\n",
    "\n",
    "            lll = screenshot_name()\n",
    "            scr.save(f\"{pathh}/{lll}.jpg\")\n",
    "            time.sleep(3)\n",
    "\n",
    "            \n",
    "        # 9.) Save (thumb gesture)\n",
    "        if np.sum(fingers) == 1 and fingers[0] == 1 and fingers[1] == 0 and fingers[3] == 0 and fingers[4] == 0 and fingers[2] == 0:\n",
    "            pyautogui.keyDown('ctrl')\n",
    "            pyautogui.press('s')\n",
    "            pyautogui.keyUp('ctrl')\n",
    "            time.sleep(2)\n",
    "        \n",
    "            \n",
    "        # 10.) (ALT + F4) ( index + thumb gesture )\n",
    "        if np.sum(fingers) == 2 and fingers[0] ==1 and fingers[1] == 1 and fingers[2] == 0 and fingers[3] == 0 and fingers[4] == 0:\n",
    "            pyautogui.getActiveWindowTitle()\n",
    "            time.sleep(0.5)\n",
    "            pyautogui.keyDown('alt')\n",
    "            pyautogui.press('F4')\n",
    "            pyautogui.keyUp('alt')\n",
    "        \n",
    "        # 11.) Restart ( Index + pinky finger gesture )\n",
    "        if fingers[0] ==0 and fingers[1] == 0 and fingers[2] == 0 and fingers[3] == 0 and fingers[4] == 0:\n",
    "            print('Restart gesture captured')\n",
    "            ws = tkinter.Tk()\n",
    "            \n",
    "            res= tkinter.messagebox.askyesno('prompt' , 'Want to leave?')\n",
    "            if res == True:\n",
    "                os.system(\"shutdown /r /t 1\")\n",
    "\n",
    "            elif res == False:\n",
    "                pass\n",
    "            else:\n",
    "                tkinter.messagebox.showerror('error', 'somthing went wrong!')\n",
    "            \n",
    "            ws.destroy()\n",
    "            ws.mainloop()\n",
    "\n",
    "            \n",
    "        cv2.putText(img, '1. Brightness (Index Finger)', (17, 30),\n",
    "                    cv2.FONT_HERSHEY_COMPLEX, 0.5, (255, 0, 0), 1)\n",
    "        cv2.putText(img, '2. Volume (V-Sign)', (17, 55),\n",
    "                    cv2.FONT_HERSHEY_COMPLEX, 0.5, (255, 0, 0), 1)\n",
    "        cv2.putText(img, '3. Screenshot (index + pinky + thumb)', (17, 75),\n",
    "                    cv2.FONT_HERSHEY_COMPLEX, 0.5, (255, 0, 0), 1)\n",
    "        cv2.putText(img, '4. shut-down (pinky finger)', (17, 95),\n",
    "                    cv2.FONT_HERSHEY_COMPLEX, 0.5, (255, 0, 0), 1)\n",
    "        cv2.putText(img, '5. Save (Thumb)', (17, 115),\n",
    "                    cv2.FONT_HERSHEY_COMPLEX, 0.5, (255, 0, 0), 1) \n",
    "        cv2.putText(img, '6. Minimize - Maximize (4-fingers)', (17, 135),\n",
    "                    cv2.FONT_HERSHEY_COMPLEX, 0.5, (255, 0, 0), 1)\n",
    "        cv2.putText(img, '7. Restart (Index + pinky)', (17, 155),\n",
    "                    cv2.FONT_HERSHEY_COMPLEX, 0.5, (255, 0, 0), 1)\n",
    "        cv2.putText(img, '8. Undo (thumb + pinky)', (17, 175),\n",
    "                    cv2.FONT_HERSHEY_COMPLEX, 0.5, (255, 0, 0), 1)\n",
    "        cv2.putText(img, '9. Zoom (First Three fingers)', (17, 195),\n",
    "                    cv2.FONT_HERSHEY_COMPLEX, 0.5, (255, 0, 0), 1)\n",
    "        cv2.putText(img, '10. Play-Pause (Last three finger )', (17, 215),\n",
    "                    cv2.FONT_HERSHEY_COMPLEX, 0.5, (255, 0, 0), 1)\n",
    "        cv2.putText(img, '11. (ALT + F4) (index + thumb)', (17, 235),\n",
    "                    cv2.FONT_HERSHEY_COMPLEX, 0.5, (255, 0, 0), 1)\n",
    "        \n",
    "        cv2.imshow('img', img)    \n",
    "            \n",
    "            \n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"e\"):\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            \n",
    "# -------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Face Recongnition\n",
    "\n",
    "\n",
    "path= 'Attendees/'\n",
    "images= []\n",
    "img_names= []\n",
    "\n",
    "mylist= os.listdir(path)\n",
    "mylist= mylist[1:]\n",
    "# print(mylist)\n",
    "\n",
    "\n",
    "for classes in mylist:\n",
    "    img= cv2.imread(f'{path}/{classes}')\n",
    "    images.append(img)\n",
    "    img_names.append(os.path.splitext(classes)[0])\n",
    "# print(img_names)\n",
    "\n",
    "encodlist= []\n",
    "def find_encodings(images):\n",
    "#     encodlist= []\n",
    "    for img in images:\n",
    "        img= cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        encods= face_recognition.face_encodings(img)[0]\n",
    "        encodlist.append(encods)\n",
    "    \n",
    "    return encodlist\n",
    "find_encodings(images)\n",
    "\n",
    "def face_matching():\n",
    "    cap= cv2.VideoCapture(0)\n",
    "    while True:\n",
    "            frame, im= cap.read()\n",
    "            img= cv2.resize(im, (0,0), None, 0.25, 0.25)\n",
    "            img= cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            curfaces_in_frame= face_recognition.face_locations(img)\n",
    "            encod_curframe= face_recognition.face_encodings(img, curfaces_in_frame) #finding encodings of img & current frame\n",
    "\n",
    "            for encodface, face_loc in zip(encod_curframe,curfaces_in_frame):\n",
    "                match= face_recognition.compare_faces(encodlist, encodface)\n",
    "                facedis= face_recognition.face_distance(encodlist, encodface)\n",
    "    #             print(facedis) # prints face distance\n",
    "                match_index= np.argmin(facedis)\n",
    "                face_name= img_names[match_index]\n",
    "\n",
    "                if match[match_index]:\n",
    "                    print(f\"Approved, {face_name}'s Face Detected\")\n",
    "\n",
    "                    return True\n",
    "                    cap.release()\n",
    "                else:\n",
    "                    print('Accses Denied')\n",
    "                    cap.release()\n",
    "                    return False\n",
    "                \n",
    "                \n",
    "\n",
    "# Release the camera and all resources\n",
    "\n",
    "                \n",
    "# --------------------------------------------------------------------------------------------------\n",
    "\n",
    "            \n",
    "if face_matching():\n",
    "    stat = slide()\n",
    "print(stat)\n",
    "if stat == 1:\n",
    "    status = []\n",
    "    stat = 0\n",
    "    brightness()\n",
    "if stat == 1 and status[0] == 2:\n",
    "    status = []\n",
    "    stat = 0\n",
    "    volume()\n",
    "if stat == 1 and status[0] == 3:\n",
    "    status = []\n",
    "    \n",
    "    stat = 0\n",
    "    zoom()\n",
    "if stat == 1 and status[0] == 4:\n",
    "    status= []\n",
    "    stat = 0\n",
    "    min_max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip uninstall mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
